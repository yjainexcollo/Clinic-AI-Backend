#!/usr/bin/env python3
"""
Verification script for Azure AI Foundry integration.

Tests Azure OpenAI connectivity and logs to Application Insights.
"""
import asyncio
import os
import sys
from pathlib import Path

# Add the src directory to the Python path
script_dir = Path(__file__).parent
backend_dir = script_dir.parent
src_dir = backend_dir / "src"
sys.path.insert(0, str(src_dir))

# Load environment variables from .env if it exists
env_file = backend_dir / ".env"
if env_file.exists():
    from dotenv import load_dotenv

    load_dotenv(env_file)

import time

from clinicai.core.ai_factory import get_ai_client
from clinicai.core.config import get_settings


async def main():
    print("ğŸ” Verifying Azure AI Foundry integration...\n")

    try:
        client = get_ai_client()
        print("âœ… Client initialized successfully")

        # Get endpoint and API version from settings
        settings = get_settings()
        endpoint = settings.azure_openai.endpoint or "unknown"
        api_version = settings.azure_openai.api_version or "unknown"
        deployment = settings.azure_openai.deployment_name or "unknown"

        print(f"ğŸ“ Endpoint: {endpoint}")
        print(f"ğŸ”– API Version: {api_version}")
        print(f"ğŸ¤– Deployment: {deployment}\n")

        print("ğŸš€ Sending test request to Azure OpenAIâ€¦")
        start_time = time.time()

        # AzureAIClient.chat() returns just the response, not a tuple
        response = await client.chat(
            messages=[{"role": "user", "content": "Say OK only."}],
            max_tokens=5,
            temperature=0.0,
        )

        latency = time.time() - start_time

        print("âœ… Response: OK")
        print(f"ğŸ†” Request ID: {response.id}")
        print(f"ğŸ“Š Prompt tokens: {response.usage.prompt_tokens}")
        print(f"ğŸ“Š Completion tokens: {response.usage.completion_tokens}")
        print(f"ğŸ“Š Total tokens: {response.usage.total_tokens}")
        print(f"â±ï¸  Latency: {latency*1000:.2f}ms")
        print(f"ğŸ Finish reason: {response.choices[0].finish_reason}")
        print(f"\nğŸ’¬ Response content: {response.choices[0].message.content}")

        print("\nğŸ”— Next steps:")
        print(
            f"   - Azure AI Foundry â†’ Monitoring â†’ Requests â†’ filter by Request ID `{response.id}` or deployment `{deployment}`"
        )
        print(
            f"   - Log Analytics â†’ Logs â†’ run: AzureOpenAIRequests | where RequestId == '{response.id}'"
        )
        print(
            "   - Application Insights â†’ Logs â†’ query dependencies by operation_Id to cross-check"
        )
        print(
            "\nâœ… Foundry verification complete! Data should be visible in all three surfaces within a few minutes."
        )

    except Exception as e:
        print(f"\nâŒ Verification failed: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
